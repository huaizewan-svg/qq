import streamlit as st
import google.generativeai as genai

# =========================================================
# ğŸ”´ æ ¸å¿ƒåŒºåŸŸï¼šè¿™é‡Œå†³å®šäº†ä½ çš„ App é•¿ä»€ä¹ˆæ ·
# =========================================================

# 1. ä½ çš„ API Key (ä¸ºäº†æœ‹å‹èƒ½ç”¨ï¼Œè¯·ä¿ç•™è¿™ä¸ª key åœ¨è¿™é‡Œ)
MY_API_KEY = "AIzaSyB2BjC7ueRjbWW3Uk_Sym47rTroEUra4gk"

# 2. ç²˜è´´ä½ åœ¨ç¬¬ä¸€æ­¥é‡Œå¾—åˆ°çš„ã€ç»ˆæå›¾çº¸ã€‘
# æŠŠé‚£ä¸€å¤§æ®µæ–‡å­—å…¨éƒ¨ç²˜è´´åˆ°ä¸‹é¢ä¸‰ä¸ªå¼•å·ä¸­é—´ï¼
SYSTEM_PROMPT = """
åœ¨æ­¤å¤„ç²˜è´´ AI åˆšåˆšå¸®ä½ æ€»ç»“çš„é‚£æ®µã€ç»ˆæç³»ç»ŸæŒ‡ä»¤ã€‘ã€‚
ä¾‹å¦‚ï¼šä½ æ˜¯ä¸€ä¸ªç²¾é€š....çš„åŠ©æ‰‹ï¼Œä½ çš„å›ç­”å¿…é¡»....
"""

# 3. ä½ çš„ App åå­— (æ˜¾ç¤ºåœ¨ç½‘é¡µæ ‡é¢˜)
APP_TITLE = "æˆ‘çš„ AI ç¥å™¨"

# 4. åˆ›æ„ç¨‹åº¦ (Temperature)
# å¦‚æœä½ åœ¨ AI Studio æ²¡æ”¹è¿‡ï¼Œå°±ä¿æŒ 1.0ã€‚
# å¦‚æœä½ è§‰å¾—åŸæ¥çš„å¤ªå‘æ•£ï¼Œå°±æ”¹å°ç‚¹(0.5)ï¼›å¤ªæ­»æ¿ï¼Œå°±æ”¹å¤§ç‚¹(1.5)ã€‚
TEMPERATURE = 1.0

# =========================================================
# ä¸‹é¢çš„ä»£ç è´Ÿè´£æŠŠä¸Šé¢çš„â€œå›¾çº¸â€å˜æˆç½‘é¡µï¼Œä¸éœ€è¦ä¿®æ”¹
# =========================================================

st.set_page_config(page_title=APP_TITLE, page_icon="âœ¨", layout="centered")
st.title(f"âœ¨ {APP_TITLE}")

# éšè—å³ä¸Šè§’çš„èœå•å’Œé¡µè„šï¼Œè®©ç•Œé¢æ›´åƒä¸€ä¸ªç‹¬ç«‹ App
hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# é…ç½® AI
try:
    genai.configure(api_key=MY_API_KEY)
    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash-preview-09-2025",
        generation_config={"temperature": TEMPERATURE},
        system_instruction=SYSTEM_PROMPT
    )
except Exception as e:
    st.error(f"ç³»ç»Ÿé…ç½®å‡ºé”™: {e}")

# åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

# å±•ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# æ¥æ”¶ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("å¼€å§‹å¯¹è¯..."):
    # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # è°ƒç”¨ AI
    try:
        # å°†èŠå¤©å†å²è½¬æ¢ä¸º Gemini æ ¼å¼
        history_for_gemini = []
        for msg in st.session_state.messages[:-1]: # ä¸åŒ…å«åˆšå‘çš„è¿™ä¸€æ¡
            role = "user" if msg["role"] == "user" else "model"
            history_for_gemini.append({"role": role, "parts": [msg["content"]]})

        chat = model.start_chat(history=history_for_gemini)
        
        with st.chat_message("model"):
            with st.spinner("å¯¹æ–¹æ­£åœ¨æ€è€ƒ..."):
                response = chat.send_message(prompt)
                st.markdown(response.text)
        
        st.session_state.messages.append({"role": "model", "content": response.text})
        
    except Exception as e:
        st.error(f"è¿æ¥ä¸­æ–­ï¼Œè¯·é‡è¯•ã€‚({e})")
